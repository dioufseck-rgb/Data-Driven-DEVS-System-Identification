AutoTwin: Data-Driven DEVS System Identification
AutoTwin is an automated framework that reverse-engineers simulation models from raw tabular data.
It combines Causal Discovery (to identify system structure), Machine Learning (to learn system physics/logic), and a DEVS-inspired Simulator (to execute the coupled models). This allows you to generate a functioning Digital Twin from a CSV file and run "What-If" scenarios on systems you don't fully understand.
ðŸš€ Key Features
Automated Causal Discovery: Uses Granger Causality to determine which variables drive others (Structure Learning).
Hybrid Data Support: Handles both Numeric (Continuous) and Categorical (Discrete/Logic) data types automatically using generic pipelines.
Modular Learning: Decomposes the system into atomic subsystems and trains specific Random Forest models for each.
DEVS Simulation Engine: A discrete-time execution engine that couples the learned models to simulate future states.
Scenario Injection: Allows users to override specific variables (inputs) to test "What-If" scenarios (e.g., What happens if I turn the system to TURBO mode?).
ðŸ“‚ Project Structure
code
Text
AutoTwin/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generator.py         # Creates synthetic "Ground Truth" data (Power Plant)
â”‚   â”œâ”€â”€ structure_learner.py # Step 1: Discovers the wiring (Causal Graph)
â”‚   â”œâ”€â”€ behavior_learner.py  # Step 2: Learns the math/logic (ML Models)
â”‚   â””â”€â”€ simulator.py         # Step 3: Runs the Digital Twin (Execution Engine)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synthetic_plant.csv  # Generated input data
â”‚
â”œâ”€â”€ models/                  # Stores trained .pkl models
â”‚   â”œâ”€â”€ model_boiler_temp.pkl
â”‚   â””â”€â”€ model_turbine_rpm.pkl
â”‚
â”œâ”€â”€ plots/                   # Visual outputs
â”‚   â”œâ”€â”€ structure_graph.png
â”‚   â””â”€â”€ simulation_hybrid.png
â”‚
â”œâ”€â”€ README.md                # Documentation
â””â”€â”€ requirements.txt         # Dependencies
ðŸ› ï¸ Installation
Clone the repository (or create the folder).
Install dependencies:
code
Bash
pip install pandas numpy scikit-learn networkx matplotlib statsmodels
ðŸš¦ Usage Pipeline
The system works in a 3-stage pipeline: Generate -> Learn -> Simulate.
1. Data Generation (Ground Truth)
Create a synthetic dataset representing a Thermal Power Plant. This plant has a Fuel Valve (Numeric) and an Operation Mode (Categorical: ECO, TURBO, OFF) that affect a Boiler and Turbine.
code
Bash
python src/generator.py
Output: Creates synthetic_plant.csv with frequent mode switching to ensure rich training data.
2. Learning Phase (Structure & Behavior)
This script first runs the Structure Learner to build the dependency graph, then runs the Behavior Learner to train ML pipelines for every identified subsystem.
code
Bash
python src/behavior_learner.py
Output:
Generates plots/structure_graph.png (The Blueprint).
Saves trained models to models/.
Note: Look for "âœ… SUCCESS" in the console confirming the link between operation_mode and boiler_temp.
3. Simulation Phase (The Digital Twin)
Run the simulator with a specific "What-If" scenario. The current script simulates a scenario where Fuel is constant, but the Operation Mode switches from ECO 
â†’
â†’
 TURBO 
â†’
â†’
 OFF.
code
Bash
python src/simulator.py
Output: Generates plots/simulation_hybrid.png.
ðŸ“Š Understanding the Results
The Structure Graph (plots/structure_graph.png)
The system automatically discovers the physical connections:
fuel_valve 
â†’
â†’
 boiler_temp
operation_mode 
â†’
â†’
 boiler_temp
boiler_temp 
â†’
â†’
 turbine_rpm
The Simulation Plot (plots/simulation_hybrid.png)
The final validation shows the Digital Twin in action:
Green Zone (ECO): System behaves normally.
Yellow Zone (TURBO): The Boiler Temp spikes significantly, even though Fuel Input remained constant. This proves the AI learned the logic of "Turbo Mode."
Gray Zone (OFF): The system cools down immediately, overriding the fuel input.
ðŸ§  How it Works (Under the Hood)
Granger Causality: The system iterates through every pair of columns in the CSV. It tests if the past values of Column A help predict Column B significantly better than Column B's own history.
Graph Construction: Significant links form a Directed Graph. Transitive Reduction is applied to remove "shortcuts" (
A
â†’
C
Aâ†’C
 is removed if 
A
â†’
B
â†’
C
Aâ†’Bâ†’C
 exists).
Hybrid ML Pipeline:
For every node in the graph, we identify its parents (Inputs).
We construct a scikit-learn Pipeline:
Categorical Inputs 
â†’
â†’
 OneHotEncoder
Numeric Inputs 
â†’
â†’
 Passthrough
Model 
â†’
â†’
 RandomForestRegressor
The model learns: 
S
t
a
t
e
t
=
f
(
S
t
a
t
e
t
âˆ’
1
,
I
n
p
u
t
s
t
âˆ’
1
)
State 
t
â€‹
 =f(State 
tâˆ’1
â€‹
 ,Inputs 
tâˆ’1
â€‹
 )
DEVS Simulation: The engine initializes the state. At every time step 
t
t
, it:
Accepts external scenario overrides.
Passes current states to connected blocks.
Calculates 
t
+
1
t+1
 for all blocks.
Commits the new state.
